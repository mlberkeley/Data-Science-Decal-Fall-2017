{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Decal, Fall 2017\n",
    "## Day 3: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBA Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nba_sals = pd.read_csv(\"./nbasalary.csv\", index_col = 0)\n",
    "nba_sals = nba_sals.dropna(axis=0)\n",
    "nba_sals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_wage = nba_sals[\"lwage\"]\n",
    "wage = nba_sals[\"wage\"]\n",
    "points = nba_sals[\"points\"]\n",
    "exper = nba_sals[\"exper\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this section, we will compare two SLR models and see which one performs better on a validation set. \n",
    "##### Model 1: Regressing wage on points scored\n",
    "##### Model 2: Regressing wage on years of experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.scatter(points,wage)\n",
    "plt.title(\"Wage vs. Points\")\n",
    "plt.xlabel(\"Points\")\n",
    "plt.ylabel(\"Wage\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.scatter(exper,wage)\n",
    "plt.title(\"Wage vs. Experience\")\n",
    "plt.xlabel(\"Experience\")\n",
    "plt.ylabel(\"Wage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "myOLS_points = sm.OLS(wage,points).fit()\n",
    "plt.plot(points, myOLS_points.predict(points), color = 'red')\n",
    "plt.scatter(points, wage)\n",
    "plt.title(\"Wage vs. Points\")\n",
    "plt.xlabel(\"Points\")\n",
    "plt.ylabel(\"Wage\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(2)\n",
    "myOLS_exper = sm.OLS(wage,exper).fit()\n",
    "plt.plot(exper, myOLS_exper.predict(exper), color = 'red')\n",
    "plt.scatter(exper, wage)\n",
    "plt.title(\"Wage vs. Expereince\")\n",
    "plt.xlabel(\"Experience\")\n",
    "plt.ylabel(\"Wage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little validation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wage_train = nba_sals[\"wage\"][0:214]\n",
    "wage_valid = nba_sals[\"wage\"][214:]\n",
    "points_train = nba_sals[\"points\"][0:214]\n",
    "points_valid = nba_sals[\"points\"][214:]\n",
    "exper_train = nba_sals[\"exper\"][0:214]\n",
    "exper_valid = nba_sals[\"exper\"][214:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression wage on points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myOLS = sm.OLS(wage_train,points_train).fit()\n",
    "wage_hat = myOLS.predict(points_valid)\n",
    "mse = 1/len(wage_valid)*np.dot((wage_valid - wage_hat),(wage_valid - wage_hat))\n",
    "print(\"The MSE for the model wage~points is:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressing wage on experience..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myOLS = sm.OLS(wage_train,exper_train).fit()\n",
    "wage_hat = myOLS.predict(exper_valid)\n",
    "mse = 1/len(wage_valid)*np.dot((wage_valid - wage_hat),(wage_valid - wage_hat))\n",
    "print(\"The MSE for the model wage~experience is:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion: points scored is a better predictor of wage than years of experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wage vs. Experience & Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_dat = nba_sals[[\"exper\",\"points\"]]\n",
    "exp_dat = sm.add_constant(exp_dat)\n",
    "myMLR = sm.OLS(wage, exp_dat).fit()\n",
    "myMLR.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x1, x2 = np.meshgrid(np.linspace(exp_dat.exper.min(), exp_dat.exper.max(), 100), \n",
    "                       np.linspace(exp_dat.points.min(), exp_dat.points.max(), 100))\n",
    "\n",
    "x3 = myMLR.params[0] + myMLR.params[1] * x1 + myMLR.params[2] * x2\n",
    "\n",
    "# create matplotlib 3d axes\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "my3D = Axes3D(fig, azim=-120, elev=20)\n",
    "\n",
    "# plot hyperplane\n",
    "surf = my3D.plot_surface(x1, x2, x3, cmap=plt.cm.RdBu_r, alpha=0.5, linewidth=0.5)\n",
    "\n",
    "# plot data points\n",
    "resid = wage - myMLR.predict(exp_dat)\n",
    "my3D.scatter(exp_dat[resid >= 0].exper, exp_dat[resid >= 0].points, wage[resid >= 0], color='black', alpha=1.0, facecolor='white')\n",
    "my3D.scatter(exp_dat[resid < 0].exper, exp_dat[resid < 0].points, wage[resid < 0], color='black', alpha=1.0)\n",
    "\n",
    "# set axis labels\n",
    "my3D.set_xlabel('experience')\n",
    "my3D.set_ylabel('points')\n",
    "my3D.set_zlabel('wage')\n",
    "my3D.set_title('Regression Plane in 3D')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals vs. fitted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wage_hat = myMLR.predict(exp_dat)\n",
    "resids = wage - wage_hat\n",
    "\n",
    "# Line of best fit should be Y = 0\n",
    "residOLS = sm.OLS(resids,wage_hat).fit()\n",
    "\n",
    "# Residuals vs. fitted falues\n",
    "plt.plot(wage_hat, residOLS.predict(wage_hat))\n",
    "plt.scatter(wage_hat, resids)\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.title(\"Residuals vs. Fitted Values\")\n",
    "plt.plot(wage_hat, np.repeat(2,len(wage_hat)),color = \"r\")\n",
    "plt.plot(wage_hat, np.repeat(-2,len(wage_hat)),color = \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(resids, bins = 20, normed= True, facecolor='green', alpha=0.5)\n",
    "\n",
    "## pdf of a normal(0, std(resids))\n",
    "y = mlab.normpdf( bins, np.mean(resids), np.std(resids))\n",
    "l = plt.plot(bins, y, 'r', linewidth=2)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the API: \"Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.\"\n",
    "##### \"First, the estimator is trained on the initial set of features and weights are assigned to each one of them. Then, features whose absolute weights are the smallest are pruned from the current set features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\"\n",
    "##### RFECV performs RFE with a cross-validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see what we have to work with...\n",
    "nba_sals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's pick a subset\n",
    "nba_dat = nba_sals[[\"exper\", \"games\",\"minutes\",\"forward\",\"center\",\"points\",\"guard\",\"age\"]]\n",
    "nba_dat = sm.add_constant(nba_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myReg = LinearRegression()\n",
    "myRFE = RFECV(myReg, step = 1, cv = 5)\n",
    "myRFE = myRFE.fit(nba_dat[[1,2,3,4,5,6,7,8]], wage)\n",
    "\n",
    "print(myRFE.support_)\n",
    "print(myRFE.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myMLR2 = sm.OLS(wage, nba_dat[[0,1,5,6,7]]).fit()\n",
    "myMLR2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get the MSE of our best model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "nba_sals_train = nba_dat[0:214]\n",
    "nba_sals_valid = nba_dat[214:]\n",
    "\n",
    "wage_train = nba_sals[\"wage\"][0:214]\n",
    "wage_valid = nba_sals[\"wage\"][214:]\n",
    "\n",
    "nba_dat_train = nba_sals_train[[0,1,5,6,7]]\n",
    "nba_dat_train = sm.add_constant(nba_dat_train)\n",
    "\n",
    "nba_dat_valid = nba_sals_valid[[0,1,5,6,7]]\n",
    "nba_dat_valid = sm.add_constant(nba_dat_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wage_hat = myMLR2.predict(nba_dat_valid)\n",
    "mse = 1/len(wage_valid)*np.dot((wage_valid - wage_hat),(wage_valid - wage_hat))\n",
    "print(\"The MSE of our best model is:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Data: Three physiological and three \n",
    "#       exercise variables are measured on \n",
    "#       twenty middle-aged men in a fitness club.\n",
    "linnerud_dat = datasets.load_linnerud()\n",
    "x_linnerud = linnerud_dat['data']\n",
    "y_linnerud = linnerud_dat['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def poly_reg(x, y, degree = 1):\n",
    "    # Add a bias term to the dataset\n",
    "    x = sm.add_constant(x)\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly_feats = PolynomialFeatures(degree)\n",
    "    x = poly_feats.fit_transform(x)\n",
    "    \n",
    "    # Split into training and validation set\n",
    "    split = int(0.8*x.shape[0])\n",
    "    x_train, x_val = x[0:split, ], x[split:, ]\n",
    "    y_train, y_val = y[:split, ], y[split:, ]\n",
    "    \n",
    "    # Fit the polynomial regression model\n",
    "    my_reg = sm.OLS(y_train, x_train).fit()\n",
    "    \n",
    "    # Make predictions\n",
    "    val_preds = my_reg.predict(x_val)\n",
    "    train_preds = my_reg.predict(x_train)\n",
    "    val_mse = mean_squared_error(y_val, val_preds)\n",
    "    train_mse = mean_squared_error(y_train, train_preds)\n",
    "    print(\"Degree:\", degree, \"\\n\", \n",
    "          \"Train MSE:\", train_mse, \"\\n\", \"Valid MSE:\", val_mse) \n",
    "    \n",
    "    return train_mse, val_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deg_list = [1, 2, 3, 4, 5]\n",
    "t_mse, v_mse = [], []\n",
    "for deg in deg_list:\n",
    "    t, v = poly_reg(x_linnerud, y_linnerud, deg)\n",
    "    t_mse.append(t)\n",
    "    v_mse.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot1 = plt.plot(degree_list, np.log(t_mse), '-ob', label = 'train')\n",
    "plot2 = plt.plot(degree_list, np.log(v_mse), '-or', label = 'valid')\n",
    "plt.ylabel(\"Log(MSE)\")\n",
    "plt.xlabel(\"Degree of polynomial features\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net regression\n",
    "#### A combination of $L_1$ and $L_2$ regularization\n",
    "##### $$\\hat{\\theta} = argmin_{\\theta} ||y- X\\theta||_2^2 + \\lambda_1 ||\\theta||_2^2 + \\lambda_2||\\theta||_1 $$\n",
    "\n",
    "\n",
    "##### $$ \\lambda_1 = \\alpha * L_1\\text{ ratio} $$\n",
    "##### $$ \\lambda_2 = 0.5 * \\alpha  * (1 - L_1\\text{ ratio} )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Back to NBA data...\n",
    "y_nba = nba_sals['wage']\n",
    "x_nba = nba_sals.drop('wage', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def elastic_net(x, y, alph = 0.1, l1_ratio = 0.8):\n",
    "    # Add a bias term to the dataset\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    x = sm.add_constant(x)\n",
    "\n",
    "    # Split into training and validation set\n",
    "    split = int(0.8*x.shape[0])\n",
    "    x_train, x_val = x[0:split, ], x[split:, ]\n",
    "    y_train, y_val = y[:split, ], y[split:, ]\n",
    "    \n",
    "    # Fit the elastic net regression model\n",
    "    my_reg = ElasticNet(alpha = alph,l1_ratio = l1_ratio, \n",
    "                        max_iter = 1e5).fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    val_preds = my_reg.predict(x_val)\n",
    "    train_preds = my_reg.predict(x_train)\n",
    "    val_mse = mean_squared_error(y_val, val_preds)\n",
    "    train_mse = mean_squared_error(y_train, train_preds)\n",
    "    print(\"Alpha:\", alph, \"\\n\", \n",
    "          \"Train MSE:\", train_mse, \"\\n\", \"Valid MSE:\", val_mse) \n",
    "    \n",
    "    return train_mse, val_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alph_list = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "t_mse, v_mse = [], []\n",
    "for alph in alph_list:\n",
    "    t, v = elastic_net(x_nba, y_nba, alph)\n",
    "    t_mse.append(t)\n",
    "    v_mse.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot1 = plt.plot(alph_list, t_mse, '-ob', label = 'train')\n",
    "plot2 = plt.plot(alph_list, v_mse, '-or', label = 'valid')\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
